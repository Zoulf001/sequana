"""ChIPseq pipeline

Affiliation: Institut Pasteur @ 2018

This pipeline is part of Sequana software (sequana.readthedocs.io)
"""

import sequana
from os.path import join
from sequana import snaketools as sm
import pandas as pd
from fnmatch import fnmatch
from re import sub
from itertools import repeat, chain, product

sm.init("chipseq.rules", globals())

# This must be defined before the include
configfile: "config.yaml"
__snakefile__ = srcdir(__snakefile__)

# Generic include of some dynamic modules
exec(open(sequana.modules["fastqc_dynamic"], "r").read())
exec(open(sequana.modules["bowtie2_mapping_dynamic"], "r").read())
exec(open(sequana.modules["bowtie2_index_dynamic"], "r").read())
exec(open(sequana.modules["dynamic_unpigz"], "r").read())
exec(open(sequana.modules["dynamic_copy"], "r").read())
exec(open(sequana.modules["macs2_dynamic"], "r").read())
exec(open(sequana.modules["preIDR_dynamic"], "r").read())
exec(open(sequana.modules["mark_duplicates_dynamic"], "r").read())

manager = sm.PipelineManager("chipseq", config)



# Check the design file
__design__ = manager.config.design.design_file

design = pd.read_csv(__design__, header=0, sep='\t')



"""
REQUIREMENTS IN DESIGN:
 - all files in one directory
 - fullname of files must be :
        MARK_COND_REP_READ-TAG.fastq.gz
 - name on design must be:
        MARK_COND


"""

#get all fastq
__data__input = manager.getrawdata()


#get list of input files
INPUT = []
for row in design.itertuples(index=True, name='Pandas'):
    for file in manager.ff.filenames:
        mark = getattr(row, "INPUT_NAME")
        if not pd.isna(mark):
            if fnmatch(file, mark+"*1_*"):
                i = 1
                name = sub(manager.ff.read_tag, '', file)
                INPUT.append(name)
                if getattr(row, "NB_IP") > 1 :
                    while i < getattr(row, "NB_IP"):
                        INPUT.append(name)
                        i += 1

#get list of IP files
IP_ALL = []
for mark in design['IP_NAME']:
    for file in manager.ff.filenames:
        if fnmatch(file, mark+"*") and file not in IP_ALL:
            name = sub(manager.ff.read_tag, '', file)
            IP_ALL.append(name)


# get REP names
#get list with replicates names for all IP
rep_flag = manager.config.design.replicates
rep = [rep_flag+'1', rep_flag+'2']
# deduce from rep the list for SPR & PPR
ppr = ['PPR1', 'PPR2', 'PPRPool']
spr = ['SPR1.1', 'SPR1.2', 'SPR2.1', 'SPR2.2']

#check design
# get marks and conds for the union of optimal peaks
marks = [ x.strip() for x in (manager.config.design.marks).split(",")]
conds = [ x.strip() for x in (manager.config.design.condition).split(",")]

# Select mark for statistical analysis if there is more than one condition (with min 2 rep) for each mark
MARK_OK =[]
for row in design.itertuples(index=True, name='Pandas'):
    for mark in marks:
        if mark == getattr(row, "IP_NAME").split("_")[0]:
            if (getattr(row, "IP_NAME")).endswith(tuple(conds)) and getattr(row, "NB_IP") > 1:
                MARK_OK.append(mark)

#built list of MARK_COND_REP from config.yaml and check correspondance between design, config and fastq files

if len(conds) > 1 :
#built list of MARK_COND_REP from config.yaml
    conf_cond = ["{mark}_{cond}_{flag}".format(cond=cond, mark=mark, flag=rep_flag) for cond in conds for mark in marks]
    for row in design.itertuples(index=True, name='Pandas'):
        for elem in conf_cond:
            if elem in getattr(row, "IP_NAME"):
                raise ValueError("Please check correspondance between config and design file: %s is not %s "
                                 % (elem,getattr(row, "IP_NAME")))
            elif not any(elem in s for s in manager.ff.tags):
                raise ValueError("Please check correspondance between config file and fastq filenames: %s not found in %s"
                                 % (elem, manager.ff.tags))
            elif sum(getattr(row, "IP_NAME") in s for s in manager.ff.tags) is not int(getattr(row, "NB_IP")):
                raise ValueError("Please check correspondance between number of replicates and/or prefix names in design "
                                 "file and fastq filenames: %s not found %s times in %s" % (getattr(row, "IP_NAME"),
                                                                                             getattr(row, "NB_IP"),manager.ff.tags))
else :
    #todo what we do ??!!
    pass


# From the design file, we get only IP with more than one replicate and at least one INPUT
IP_REP = [] # all IP passing IDR
IP_REP_DUP = [] # corresponding INPUT
IP_NO_INPUT = [] # all IP with replicates but without INPUT
INPUT_NA = [] # corresponding INPUT (list of NA according to number of IP)
IP_NA = [] # all IP without replicates and without INPUT
for row in design.itertuples(index=True, name='Pandas'):
    if getattr(row, "NB_IP") > 1 and getattr(row, "NB_INPUT") >= 1:
        IP_REP_DUP.append(getattr(row, "INPUT_NAME")+"_"+rep_flag+"1")
        IP_REP.append(getattr(row, "IP_NAME"))
    if getattr(row, "NB_IP") > 1 and getattr(row, "NB_INPUT") < 1:
        IP_NO_INPUT.append(getattr(row, "IP_NAME"))
        INPUT_NA.append('NA')
    if getattr(row, "NB_IP") == 1 and getattr(row, "NB_INPUT") < 1:
        IP_NA.append(getattr(row, "IP_NAME"))

# We get only INPUT with more than one replicate that are linked to an IP with multiple replicates
INPUT_REP = []
for row in design.itertuples(index=True, name='Pandas'):
    if getattr(row, "NB_INPUT") > 1 and getattr(row, "NB_IP") > 1 and (getattr(row, "INPUT_NAME")) not in INPUT_REP:
        INPUT_REP.append(getattr(row, "INPUT_NAME"))

#get IP passed pre IDR step (for rep, ppr and spr)
IP_IDR = []
IP_SPR = []
IP_PPR = []
SPR_POOL = []
INPUT_SPR  = []
INPUT_PPR = []
#IDR_REP = []
for cond in IP_REP:
    tmp = []
    tmp2 = []
    for ip in IP_ALL:
        name = ip.split("_" + rep_flag)
        if ip.startswith(cond):
            spr_file = sub(rep_flag, 'SPR', ip)
            ppr_file =  sub(rep_flag, 'PPR', ip)
            pool_file = sub(rep_flag, 'PPRPool', ip)
            tmp.append(ip)
            #IDR_REP.append("Rep"+name[1])
            IP_SPR.append(spr_file+".1")
            IP_SPR.append(spr_file+".2")
            IP_PPR.append(ppr_file)
            SPR_POOL.append(pool_file)
            for row in design.itertuples(index=True, name='Pandas'):
                if  (getattr(row, "IP_NAME")) in name[0]:
                     INPUT_PPR.append(getattr(row, "INPUT_NAME")+"_"+rep[0])
                     INPUT_SPR.append(getattr(row, "INPUT_NAME")+"_"+rep[0])
                     INPUT_SPR.append(getattr(row, "INPUT_NAME")+"_"+rep[0])
    IP_IDR.append(tmp)


#get pooled IP passed pre IDR step and corresponding INPUT
PPR_POOL = []
INPUT_POOL = []
for row in design.itertuples(index=True, name='Pandas'):
    if getattr(row, "NB_IP") > 1 and getattr(row, "NB_INPUT") > 1 :
        PPR_POOL.append(getattr(row, "IP_NAME") + "_PPRPool")
        INPUT_POOL.append(getattr(row, "INPUT_NAME") + "_Pool")
    #elif getattr(row, "NB_IP") > 1 and getattr(row, "NB_INPUT") < 2 :
    elif getattr(row, "NB_IP") > 1 and getattr(row, "NB_INPUT") == 1 :
        PPR_POOL.append(getattr(row, "IP_NAME") + "_PPRPool")
        INPUT_POOL.append(getattr(row, "INPUT_NAME")+ "_" + rep_flag + "1")

# all files passing PhantomPeakQualTool if no-model is chosen
ALL = IP_ALL + IP_SPR + IP_PPR + PPR_POOL

# get files for IDR
CASE = [rep_flag, "PPR", "SPR1.", "SPR2."]*len(IP_REP)
REP_IDR = list(chain(*zip(*repeat(IP_REP,4))))
IN_IDR = list(chain(*zip(*repeat(IP_REP_DUP,4))))


# Add wildcard constraints
wildcard_constraints:
    sample = "[A-Za-z-_0-9]+_{0}[0-9]+".format(rep_flag),
    IP_REP = "[A-Za-z-_0-9]+_{0}[0-9]+".format(rep_flag),
    REP = "{0}[0-9]+".format(rep_flag),
    SPR = "[A-Za-z-_0-9]+_SPR[0-9]\.[1-4]*",
    PPR = "[A-Za-z-_0-9]+_PPR[0-9]*",
    POOL = "[A-Za-z-_0-9]+_PPRPool",
    INPUT_POOL = "[A-Za-z-_0-9]+_(Pool|{0}1)".format(rep_flag),
    MARK = "[A-Za-z-_0-9]+"

#reorder rules :
ruleorder: mark_duplicates_ref > spp > preIDR_input > preIDR_PPR > preIDR_SPR > macs2_rep > compute_idr

if manager.config.fastqc.do:
    # FASTQC on input data set
    __fastqc_raw__input_fastq = __data__input
    __fastqc_raw__output_done = "0-Fastqc/{sample}_fastqc_raw.done"
    __fastqc_raw__wkdir = "0-Fastqc"
    __fastqc_raw__log = "0-Fastqc/logs/{sample}_fastqc_raw.log"
    include: fastqc_dynamic("raw", manager)
    expected_output.extend(expand(__fastqc_raw__output_done, sample=manager.samples))

if manager.config.cutadapt.do:
    adapter_tool = manager.config.cutadapt.tool_choice

    from sequana.adapters import _get_registered_adapters as registered
    from sequana.adapters import get_sequana_adapters

    # Users may provide TruSeq, Nextera, PCRFree or other registered adapters
    fwd = manager.config.cutadapt.fwd
    if isinstance(fwd, str) and fwd in registered():
        filename = "file:" + get_sequana_adapters(fwd, "fwd")
        manager.config.cutadapt.fwd = filename

    rev = manager.config.cutadapt.rev
    if isinstance(rev, str) and rev in registered():
        filename = "file:" + get_sequana_adapters(rev, "revcomp")
        manager.config.cutadapt.rev = filename

    if adapter_tool in ["cutadapt", "atropos"]:
        adapter_tool = "cutadapt"
        __cutadapt__input_fastq = __data__input
        __cutadapt__wkdir = "1-Trimming"
        # __cutadapt__output = [manager.getname("cutadapt", "_R1_.cutadapt.fastq.gz")]
        __cutadapt__output = ["1-Trimming/{sample}_R1_trim.fastq.gz"]
        if manager.paired:
            __cutadapt__output += ["1-Trimming/{sample}_R2_trim.fastq.gz"]

        # Set the fwd and rev adapters
        __cutadapt__fwd = manager.config.cutadapt.fwd
        __cutadapt__rev = manager.config.cutadapt.rev

        __cutadapt__design = manager.config.cutadapt.design_file
        __cutadapt__design_adapter = manager.config['cutadapt']['adapter_choice']
        __cutadapt__options = manager.config.cutadapt.options
        __cutadapt__mode = manager.config.cutadapt.mode
        __cutadapt__log = "1-Trimming/logs/{sample}_trim.txt"
        __cutadapt__sample = "{sample}"
        include: sm.modules["cutadapt"]

    else:
        raise ValueError("Invalid choice of cutadapt:tool in config file. Use either atropos or cutadapt")
else:
    __cutadapt__output = __data__input

if manager.config.cutadapt.do:
    # FASTQC on trimmed data set
    __fastqc_trim__input_fastq = __cutadapt__output
    __fastqc_trim__output_done = "0-Fastqc/{sample}_fastqc_trim.done"
    __fastqc_trim__wkdir = "0-Fastqc"
    __fastqc_trim__log = "0-Fastqc/logs/{sample}_fastqc_trim.log"
    include: fastqc_dynamic("trim", manager)
    expected_output.extend(expand(__fastqc_trim__output_done, sample=manager.samples))

__prefix_name__ = os.path.join(config["genome"]["genome_directory"], config["genome"]["name"])

if manager.config.genome.index:
    # indexing for bowtie2
    __bowtie2_index_ref__fasta = config["genome"]["fasta_file"]
    __bowtie2_index_ref__output_done = __prefix_name__ + ".1.bt2"
    __bowtie2_index_ref__output_prefix = __prefix_name__
    __bowtie2_index_ref__log = "2-Mapping/logs/bowtie2_ref_indexing.log"
    include: bowtie2_index_dynamic("ref")
    expected_output.extend([__bowtie2_index_ref__output_done])
else:
    __bowtie2_index_ref__output_done = __prefix_name__ + ".1.bt2"
    __bowtie2_index_ref__output_prefix = __prefix_name__

ref = manager.config.genome.name

if manager.config.bowtie2_mapping.do:
    # Decompress fastq.gz file before to run bowtie2 ### NECESSARY ??
    __unpigz_R1__input = "1-Trimming/{sample}_R1_trim.fastq.gz"
    __unpigz_R1__output = "1-Trimming/{sample}_R1_trim.fastq"
    include: dynamic_unpigz("R1", manager)
    __unpigz__output = [__unpigz_R1__output]
    if manager.paired:
        __unpigz_R2__input = "1-Trimming/{sample}_R2_trim.fastq.gz"
        __unpigz_R2__output = "1-Trimming/{sample}_R2_trim.fastq"
        include: dynamic_unpigz("R2", manager)
        __unpigz__output += [__unpigz_R2__output]


    # mapping on ref
    __bowtie2_mapping_ref__input = __cutadapt__output
    __bowtie2_mapping_ref__index_done = __bowtie2_index_ref__output_done
    __bowtie2_mapping_ref__sort = "2-Mapping/{{sample}}_{}_sort.bam".format(ref)
    __bowtie2_mapping_ref__bam = "2-Mapping/{{sample}}_{}.bam".format(ref)
    __bowtie2_mapping_ref__logs_err = "2-Mapping/logs/{{sample}}_{}_mapping.e".format(ref)
    __bowtie2_mapping_ref__logs_out = "2-Mapping/logs/{{sample}}_{}_mapping.o".format(ref)
    __bowtie2_mapping_ref__options = config["bowtie2_mapping"]["options"]
    __bowtie2_mapping_ref__prefix_index = __bowtie2_index_ref__output_prefix
    include: bowtie2_mapping_dynamic("ref", manager)
    expected_output.extend(expand(__bowtie2_mapping_ref__sort, sample=manager.samples))

else:
    __bowtie2_mapping_ref__sort = __data__input

if manager.config.design.spike:
    # indexing for bowtie2
    __spikes_fasta = config["design"]["spike_genome_file"]
    __bowtie2_index_spike__fasta = __spikes_fasta
    __bowtie2_index_spike__output_done = os.path.splitext(__spikes_fasta)[0] + ".1.bt2"
    __bowtie2_index_spike__output_prefix = os.path.splitext(__spikes_fasta)[0]
    __bowtie2_index_spike__log = "2-Mapping/logs/bowtie2_spike_indexing.log"
    include: bowtie2_index_dynamic("spike")
    expected_output.extend([__bowtie2_index_spike__output_done])

    # mapping on spike
    __bowtie2_mapping_spike__input = __cutadapt__output
    __bowtie2_mapping_spike__index_done = __bowtie2_index_spike__output_done
    __bowtie2_mapping_spike__sort = "2-Mapping/{sample}_spike_sort.bam"
    __bowtie2_mapping_spike__bam = "2-Mapping/{sample}_spike.bam"
    __bowtie2_mapping_spike__logs_err = "2-Mapping/logs/{sample}_spike_mapping.e"
    __bowtie2_mapping_spike__logs_out = "2-Mapping/logs/{sample}_spike_mapping.o"
    __bowtie2_mapping_spike__options = manager.config.bowtie2_mapping.options
    __bowtie2_mapping_spike__prefix_index = __bowtie2_index_spike__output_prefix
    include: bowtie2_mapping_dynamic("spike", manager)
    expected_output.extend(expand(__bowtie2_mapping_spike__sort, sample=manager.samples))

    # markduplicate on spikes
    __mark_duplicates_spike__input = __bowtie2_mapping_spike__sort
    __mark_duplicates_spike__output = "3-Deduplication/{sample}_spike_sort_dedup.bam"
    __mark_duplicates_spike__metrics = "3-Deduplication/{sample}_spike_sort_dedup.txt"
    __mark_duplicates_spike__log_std = "3-Deduplication/logs/{sample}_spike_sort_dedup.o"
    __mark_duplicates_spike__log_err = "3-Deduplication/logs/{sample}_spike_sort_dedup.e"
    include: mark_duplicates_dynamic("spike", manager)
    expected_output.extend(expand(__mark_duplicates_spike__output, sample=manager.samples))


    # counting on spikes
    __spikes_counting__input = expand("3-Deduplication/{sample}_spike_sort_dedup.bam", sample=manager.samples)
    __spikes_counting__output_json = "9-CountMatrix/Spikes_count.json"
    __spikes_counting__output = "Spikes_metrics_mqc.out"
    __spikes_counting__log = "3-Deduplication/logs/Spikes_metrics.o"
    include: sm.modules["spikes_counting"]
    expected_output.extend([__spikes_counting__output_json])




# Mark duplicates
if manager.config.mark_duplicates.do:
    __mark_duplicates_ref__input = __bowtie2_mapping_ref__sort
    __mark_duplicates_ref__output = "3-Deduplication/{{sample}}_{}_sort_dedup.bam".format(ref)
    __mark_duplicates_ref__metrics = "3-Deduplication/{{sample}}_{}_sort_dedup.txt".format(ref)
    __mark_duplicates_ref__log_std = "3-Deduplication/logs/{{sample}}_{}_sort_dedup.o".format(ref)
    __mark_duplicates_ref__log_err = "3-Deduplication/logs/{{sample}}_{}_sort_dedup.e".format(ref)
    include: mark_duplicates_dynamic("ref", manager)
    expected_output.extend(expand(__mark_duplicates_ref__output, sample=manager.samples))
else:
    __mark_duplicates__output = __bowtie2_mapping_ref__sort

# Remove blacklist
# if don't, use a .format() with a variable contains "_NoBlacklist" or not.
if manager.config.remove_blacklist.do:
    blacklist = "_NoBlacklist"
    blacklist_dir = "4-NoBlacklist"
    __remove_blacklist__input = __mark_duplicates_ref__output
    __remove_blacklist__output = "4-NoBlacklist/{{sample}}_{}_sort_dedup{}.bam".format(ref, blacklist)
    __remove_blacklist__log_std = "4-NoBlacklist/logs/{{sample}}_{}_sort_dedup{}.o".format(ref, blacklist)
    __remove_blacklist__log_err = "4-NoBlacklist/logs/{{sample}}_{}_sort_dedup{}.e".format(ref, blacklist)
    include: sm.modules["remove_blacklist"]
    expected_output.extend(expand(__remove_blacklist__output, sample=manager.samples))

else:
    blacklist = ""
    blacklist_dir = "3-Deduplication"


# preIDR rules
# run preIDR on INPUT
if len(INPUT_REP) > 0:
    __preIDR_input__input_bam = expand("%s/{{INPUT}}_{REP}_%s_sort_dedup%s.bam" %
                                       (blacklist_dir,ref, blacklist), REP = rep)
    __preIDR_input__case = "Pool"
    __preIDR_input__log = "%s/logs/{{INPUT}}_preIDR_input.o" % (blacklist_dir)
    if len(rep) > 2:
        __preIDR_input__output = ["{}/{{INPUT}}_Pool_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist),
                                 "{}/{{INPUT}}_MaxiPool_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)]
    else:
        __preIDR_input__output = "{}/{{INPUT}}_Pool_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    include: preIDR_dynamic("input")
    expected_output.extend(expand(__preIDR_input__output, INPUT=INPUT_REP))


if len(IP_REP) > 0:
    # run SPR
    __preIDR_SPR__input_bam = expand("%s/{{IP}}_{REP}_%s_sort_dedup%s.bam" %
                                     (blacklist_dir,ref, blacklist) , REP = rep)
    __preIDR_SPR__case = "SPR"
    __preIDR_SPR__log = "%s/logs/{{IP}}_preIDR_SPR.o"% (blacklist_dir)
    __preIDR_SPR__output = expand("%s/{{IP}}_{SPR}_%s_sort_dedup%s.bam" % (blacklist_dir,ref, blacklist),  SPR = spr)
    include: preIDR_dynamic("SPR")
    expected_output.extend(expand(__preIDR_SPR__output, IP=IP_REP))

    # run PPR
    __preIDR_PPR__input_bam = expand("%s/{{IP}}_{REP}_%s_sort_dedup%s.bam" %
                                     (blacklist_dir,ref, blacklist), REP = rep)
    __preIDR_PPR__case = "PPR"
    __preIDR_PPR__log = "%s/logs/{IP}_preIDR_PPR.o" % (blacklist_dir)
    __preIDR_PPR__output =  expand("%s/{{IP}}_{PPR}_%s_sort_dedup%s.bam" %
                                   (blacklist_dir,ref, blacklist), PPR = ppr)
    include: preIDR_dynamic("PPR")
    expected_output.extend(expand(__preIDR_PPR__output, IP=IP_REP))

if manager.config.peak_calling.no_model:
    # PhantomPeakQualTools rule
    __spp__input = "{}/{{ALL}}_{}_sort_dedup{}.bam".format(blacklist_dir,ref, blacklist)
    __spp__output_pdf = "5-PhantomPeakQualTools/{{ALL}}_{}_sort_dedup{}_phantom.pdf".format(ref, blacklist)
    __spp__metrics = "5-PhantomPeakQualTools/{{ALL}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)
    __spp__log_std = "5-PhantomPeakQualTools/logs/{ALL}_phantom.o"
    __spp__log_err = "5-PhantomPeakQualTools/logs/{ALL}_phantom.e"
    expected_output.extend(expand(__spp__metrics, ALL=ALL))
    include: sm.modules["spp"]
else :
    # PhantomPeakQualTools rule
    __spp__input = "{}/{{ALL}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    __spp__output_pdf = "5-PhantomPeakQualTools/{{ALL}}_{}_sort_dedup{}_phantom.pdf".format(ref, blacklist)
    __spp__metrics = "5-PhantomPeakQualTools/{{ALL}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)
    __spp__log_std = "5-PhantomPeakQualTools/logs/{ALL}_phantom.o"
    __spp__log_err = "5-PhantomPeakQualTools/logs/{ALL}_phantom.e"
    expected_output.extend(expand(__spp__metrics, ALL=IP_ALL))
    include: sm.modules["spp"]

# Peak calling
model = manager.config.peak_calling.model_choice
model_dir = model
if manager.config.peak_calling.no_model:
    model_dir += "-nomodel"
if model in ["narrow", "broad"]:

    # Peak Calling on replicates
    if model in ["narrow"]:
        # add corresponding options
        __macs2_rep__options = "-p {} ".format(config["peak_calling"]['cutoff']) + config["peak_calling"]['options']
    else:
        __macs2_rep__options = "-p {} --broad --broad-cutoff {} ".format(config["peak_calling"]['cutoff'],
                            config["peak_calling"]['cutoff']) + config["peak_calling"]['options']

    __macs2_rep__input_bam = "{}/{{IP_REP}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    __macs2_rep__input_done = ["{}/{{INPUT}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)]
    if manager.config.peak_calling.no_model:
        __macs2_rep__options += " --nomodel "
        __macs2_rep__input_done = [
            "5-PhantomPeakQualTools/{{IP_REP}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)]
        __macs2_rep__shift_file = "5-PhantomPeakQualTools/{{IP_REP}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)
    else:
        __macs2_rep__shift_file = "Empty"
    if manager.paired :
        __macs2_rep__pe_mode = "no"
    else:
        __macs2_rep__pe_mode = "no"
    __macs2_rep__input = "-c {}/{{INPUT}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    __macs2_rep__log = "6-PeakCalling/{}/logs/{{IP_REP}}_vs_{{INPUT}}.o".format(model_dir)
    __macs2_rep__output = "6-PeakCalling/{}/{{IP_REP}}_vs_{{INPUT}}_peaks.{}Peak".format(model_dir, model)
    __macs2_rep__output_prefix = "6-PeakCalling/{}/{{IP_REP}}_vs_{{INPUT}}".format(model_dir)
    expected_output.extend(expand(__macs2_rep__output, zip, IP_REP=IP_ALL, INPUT=INPUT))
    include: macs2_dynamic("rep")

    # Peak Calling on SPR
    if model in ["narrow"]:
        # add corresponding options
        __macs2_spr__options = "-p {} ".format(config["peak_calling"]['cutoff']) + config["peak_calling"]['options']
    else:
        __macs2_spr__options = "-p {} --broad --broad-cutoff {} ".format(config["peak_calling"]['cutoff'],
                            config["peak_calling"]['cutoff']) + config["peak_calling"]['options']

    __macs2_spr__input_bam = "{}/{{SPR}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    __macs2_spr__input_done = ["{}/{{INPUT}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)]
    if manager.config.peak_calling.no_model:
        __macs2_spr__options += " --nomodel "
        __macs2_spr__input_done += ["5-PhantomPeakQualTools/{{SPR}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)]
        __macs2_spr__shift_file = "5-PhantomPeakQualTools/{{SPR}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)
    else:
        __macs2_spr__shift_file = "Empty"
    if manager.paired :
        __macs2_spr__pe_mode = "no"
    else:
        __macs2_spr__pe_mode = "no"
    __macs2_spr__input = "-c {}/{{INPUT}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    __macs2_spr__log = "6-PeakCalling/{}/logs/{{SPR}}_vs_{{INPUT}}.o".format(model_dir)
    __macs2_spr__output = "6-PeakCalling/{}/{{SPR}}_vs_{{INPUT}}_peaks.{}Peak".format(model_dir, model)
    __macs2_spr__output_prefix = "6-PeakCalling/{}/{{SPR}}_vs_{{INPUT}}".format(model_dir)
    expected_output.extend(expand(__macs2_spr__output, zip, SPR=IP_SPR, INPUT=INPUT_SPR))
    include: macs2_dynamic("spr")

    # Peak Calling on PPR
    if model in ["narrow"]:
        # add corresponding options
        __macs2_ppr__options = "-p {} ".format(config["peak_calling"]['cutoff']) + config["peak_calling"]['options']
    else:
        __macs2_ppr__options = "-p {} --broad --broad-cutoff {} ".format(config["peak_calling"]['cutoff'],
                            config["peak_calling"]['cutoff']) + config["peak_calling"]['options']

    __macs2_ppr__input_bam = "{}/{{PPR}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    __macs2_ppr__input_done = ["{}/{{INPUT}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)]

    if manager.config.peak_calling.no_model:
        __macs2_ppr__options += " --nomodel "
        __macs2_ppr__input_done += ["5-PhantomPeakQualTools/{{PPR}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)]
        __macs2_ppr__shift_file = "5-PhantomPeakQualTools/{{PPR}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)
    else:
        __macs2_ppr__shift_file = "Empty"
    if manager.paired :
        __macs2_ppr__pe_mode = "no"
    else:
        __macs2_ppr__pe_mode = "no"
    __macs2_ppr__input = "-c {}/{{INPUT}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    __macs2_ppr__log = "6-PeakCalling/{}/logs/{{PPR}}_vs_{{INPUT}}.o".format(model_dir)
    __macs2_ppr__output = "6-PeakCalling/{}/{{PPR}}_vs_{{INPUT}}_peaks.{}Peak".format(model_dir, model)
    __macs2_ppr__output_prefix = "6-PeakCalling/{}/{{PPR}}_vs_{{INPUT}}".format(model_dir)
    expected_output.extend(expand(__macs2_ppr__output, zip, PPR=IP_PPR, INPUT=INPUT_PPR))
    include: macs2_dynamic("ppr")

    # Peak Calling on Pool files
    if model in ["narrow"]:
        # add corresponding options
        __macs2_pool__options = "-p {} ".format(config["peak_calling"]['cutoff']) + config["peak_calling"]['options']
    else:
        __macs2_pool__options = "-p {} --broad --broad-cutoff {} ".format(config["peak_calling"]['cutoff'],
                            config["peak_calling"]['cutoff']) + config["peak_calling"]['options']

    __macs2_pool__input_bam = "{}/{{POOL}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    __macs2_pool__input_done = ["{}/{{INPUT_POOL}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)]

    if manager.config.peak_calling.no_model:
        __macs2_pool__options += " --nomodel "
        __macs2_pool__input_done += ["5-PhantomPeakQualTools/{{POOL}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)]
        __macs2_pool__shift_file = "5-PhantomPeakQualTools/{{POOL}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)
    else:
        __macs2_pool__shift_file = "Empty"
    if manager.paired :
        __macs2_pool__pe_mode = "no"
    else:
        __macs2_pool__pe_mode = "no"
    __macs2_pool__input = "-c {}/{{INPUT_POOL}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    __macs2_pool__log = "6-PeakCalling/{}/logs/{{POOL}}_vs_{{INPUT_POOL}}.o".format(model_dir)
    __macs2_pool__output = "6-PeakCalling/{}/{{POOL}}_vs_{{INPUT_POOL}}_peaks.{}Peak".format(model_dir, model)
    __macs2_pool__output_prefix = "6-PeakCalling/{}/{{POOL}}_vs_{{INPUT_POOL}}".format(model_dir)
    expected_output.extend(expand(__macs2_pool__output, zip, POOL=PPR_POOL, INPUT_POOL=INPUT_POOL))
    include: macs2_dynamic("pool")

    # Peak Calling on IP file without INPUT
    if model in ["narrow"]:
        # add corresponding options
        __macs2_no_ctl__options = "-p {} ".format(config["peak_calling"]['cutoff']) + config["peak_calling"]['options']
    else:
        __macs2_no_ctl__options = "-p {} --broad --broad-cutoff {} ".format(config["peak_calling"]['cutoff'],
                                                                          config["peak_calling"]['cutoff']) + \
                                config["peak_calling"]['options']

    __macs2_no_ctl__input_bam = "{}/{{IP_NA}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)
    __macs2_no_ctl__input_done = ["{}/{{IP_NA}}_{}_sort_dedup{}.bam".format(blacklist_dir, ref, blacklist)]

    if manager.config.peak_calling.no_model:
        __macs2_no_ctl__options += " --nomodel "
        __macs2_no_ctl__input_done += ["5-PhantomPeakQualTools/{{IP_NA}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)]
        __macs2_no_ctl__shift_file = "5-PhantomPeakQualTools/{{IP_NA}}_{}_sort_dedup{}_spp.out".format(ref, blacklist)
    else:
        __macs2_no_ctl__shift_file = "Empty"
    if manager.paired:
        __macs2_no_ctl__pe_mode = "no"
    else:
        __macs2_no_ctl__pe_mode = "no"
    __macs2_no_ctl__input = "NA"
    __macs2_no_ctl__log = "6-PeakCalling/{}/logs/{{IP_NA}}.o".format(model_dir)
    __macs2_no_ctl__output = "6-PeakCalling/{}/{{IP_NA}}_peaks.{}Peak".format(model_dir, model)
    __macs2_no_ctl__output_prefix = "6-PeakCalling/{}/{{IP_NA}}".format(model_dir)
    #expected_output.extend(expand(__macs2_no_ctl__output, IP_NA=IP_NA))
    #include: macs2_dynamic("no_ctl")


else:
    raise ValueError("Invalid choice of model for peak calling. Use either narrow or broad, or set no-model to yes")

#compute MACS2 metrics
macs2_rep = []
macs2_rep.extend(expand("6-PeakCalling/{}/{{IP_REP}}_vs_{{INPUT}}_peaks.{}Peak".format(model_dir, model), zip, IP_REP=IP_ALL, INPUT=INPUT))
__stats_peakCalling_input = macs2_rep
__stats_peakCalling_csv = "Peaks_metrics_mqc.out"
__stats_peakCalling__marks = marks
__stats_peakCalling__conds = conds
__stats_peakCalling__rep = rep_flag
__stats_peakCalling_log = "6-PeakCalling/{}/Peaks_metrics.out".format(model_dir)
include: sm.modules["stats_peakCalling"]
expected_output.extend([__stats_peakCalling_csv])


# Compute IDR
if model in ["narrow"]:
    __compute_idr__mode = "narrowPeak"
else :
    __compute_idr__mode = "broadPeak"
__compute_idr__input1 = "6-PeakCalling/{}/{{IP_IDR}}_{{CASE}}1_vs_{{INPUT}}_peaks.{}Peak".format(model_dir, model)
__compute_idr__input2 = "6-PeakCalling/{}/{{IP_IDR}}_{{CASE}}2_vs_{{INPUT}}_peaks.{}Peak".format(model_dir, model)
__compute_idr__output = "7-IDR/{}/{{IP_IDR}}_{{CASE}}1vs{{CASE}}2_{{INPUT}}_{}_{}_idr.txt".format(model_dir, ref, model)
__compute_idr__output_peak = "7-IDR/{}/{{IP_IDR}}_{{CASE}}1vs{{CASE}}2_{{INPUT}}_{}_{}_idr{}.{}Peak".format(model_dir,
    ref, model, config["compute_idr"]["thresh"], model)
__compute_idr__log = "7-IDR/%s/logs/{IP_IDR}_{CASE}1vs{CASE}2_{INPUT}_%s_idr.o" % (model_dir,model)
include: sm.modules["compute_idr"]
expected_output.extend(expand(__compute_idr__output, zip, IP_IDR=REP_IDR, CASE=CASE, INPUT=IN_IDR))



if model in ["narrow"] and not manager.config.compute_idr.intersectionApproach:
    # Select IDR peaks
    __select_peaks__input_rep = "7-IDR/{}/{{IP_IDR}}_{}1vs{}2_{{INPUT}}_{}_{}_idr{}.{}Peak".format(model_dir, rep_flag, rep_flag, ref, model, config["compute_idr"]["thresh"], model)
    __select_peaks__input_ppr = "7-IDR/{}/{{IP_IDR}}_{}1vs{}2_{{INPUT}}_{}_{}_idr{}.{}Peak".format(model_dir, "PPR", "PPR", ref, model, config["compute_idr"]["thresh"], model)
    __select_peaks__input_pool = "6-PeakCalling/{}/{{IP_IDR}}_PPRPool_vs_{{INPUT}}_peaks.{}Peak".format(model_dir, model)
    __select_peaks__logs = "8-ReproduciblePeaks/%s/logs/{IP_IDR}_vs_{INPUT}_selected_peaks.o" % model_dir
    __select_peaks__output = "8-ReproduciblePeaks/{}/{{IP_IDR}}_vs_{{INPUT}}_select.{}Peak".format(model_dir, model)
    include: sm.modules["select_peaks"]
    expected_output.extend(expand(__select_peaks__output, zip, IP_IDR=IP_REP, INPUT=IP_REP_DUP))


if model in ["broad"] or manager.config.compute_idr.intersectionApproach:
    __intersectionApproach__input_rep = expand("6-PeakCalling/%s/{{IP_IDR}}_{CASE}_vs_{{INPUT}}_peaks.%sPeak" % (model_dir, model), CASE=rep)
    __intersectionApproach__input_pool = "6-PeakCalling/{}/{{IP_IDR}}_PPRPool_vs_{{INPUT}}_peaks.{}Peak".format(model_dir, model)
    __intersectionApproach__logs = "8-ReproduciblePeaks/%s/logs/{IP_IDR}_vs_{INPUT}_BROAD-IA_peaks.o" % model_dir
    __intersectionApproach__output = "8-ReproduciblePeaks/{}/{{IP_IDR}}_vs_{{INPUT}}_BROAD-IA.{}Peak".format(model_dir, model)
    include: sm.modules["intersectionApproach"]
    expected_output.extend(expand(__intersectionApproach__output, zip, IP_IDR=IP_REP, INPUT=IP_REP_DUP))
    __select_peaks__output = __intersectionApproach__output


#Compute peak metrics
idr_peaks = []
idr_peaks.extend(expand("7-IDR/{}/{{IP_IDR}}_{{CASE}}1vs{{CASE}}2_{{INPUT}}_{}_{}_idr{}.{}Peak".format(model_dir,
                        ref,model, config["compute_idr"]["thresh"], model), zip, IP_IDR=REP_IDR, CASE=CASE, INPUT=IN_IDR))
__metrics_peaks__input = idr_peaks
__metrics_peaks__marks = marks
__metrics_peaks__conds = conds
__metrics_peaks__rep = rep_flag
__metrics_peaks__logs = "7-IDR/{}/logs/IDR_metrics.out".format(model_dir)
__metrics_peaks__output = "IDR_metrics_mqc.out"
include: sm.modules["metrics_peaks"]
expected_output.extend([__metrics_peaks__output])

if len(conds) > 1 and manager.config.differential_analysis.do:
    def getPeakFilesByMark(wildcards):
        ALL_IP = expand(__select_peaks__output, zip, IP_IDR=IP_REP, INPUT=IP_REP_DUP)
        IP_dict = {}
        for mark in marks:
            IP_dict[mark] = []
            for file in ALL_IP:
                if mark in file:
                    IP_dict[mark].append(file)

        return IP_dict[wildcards["MARK"]]



    # get union from all detected peak among all conditions for each mark
    __union_peaks__input = getPeakFilesByMark
    __union_peaks__logs = "9-CountMatrix/logs/{MARK}_Optimal_selected_peaks.o"
    if len(conds) == 2 :
        __union_peaks__output = "9-CountMatrix/{{MARK}}_{}u{}_{}.optimal.{}Peak_overlap.bed".format(conds[0], conds[1], ref, model)
    elif len(conds) == 3 :
        __union_peaks__output = "9-CountMatrix/{{MARK}}_{}u{}u{}_{}.optimal.{}Peak_overlap.bed".format(conds[0], conds[1], conds[2], ref, model)
    else :
       __union_peaks__output = "9-CountMatrix/{{MARK}}_all_conds_{}.optimal.{}Peak_overlap.bed".format(ref, model)

    include: sm.modules["union_peaks"]
    expected_output.extend(expand(__union_peaks__output, MARK=MARK_OK))


    # get GFF from peak files
    if len(conds) == 2 :
        __bed_to_gff__input = "9-CountMatrix/{{MARK}}_{}u{}_{}.optimal.{}Peak_overlap.bed".format(conds[0], conds[1], ref, model)
        __bed_to_gff__output = "9-CountMatrix/{{MARK}}_{}u{}_{}.optimal.{}Peak_overlap.gff".format(conds[0], conds[1], ref, model)
    elif len(conds) == 3 :
        __bed_to_gff__input = "9-CountMatrix/{{MARK}}_{}u{}u{}_{}.optimal.{}Peak_overlap.bed".format(conds[0], conds[1], conds[2],  ref, model)
        __bed_to_gff__output = "9-CountMatrix/{{MARK}}_{}u{}u{}_{}.optimal.{}Peak_overlap.gff".format(conds[0], conds[1], conds[2], ref, model)
    else :
        __bed_to_gff__input = "9-CountMatrix/{{MARK}}_all_conds_{}.optimal.{}Peak_overlap.bed".format(ref, model)
        __bed_to_gff__output = "9-CountMatrix/{{MARK}}_all_conds_{}.optimal.{}Peak_overlap.gff".format(ref, model)

    __bed_to_gff__logs = "9-CountMatrix/logs/{MARK}_Optimal_bed2gff.o"
    include: sm.modules["bed_to_gff"]
    expected_output.extend(expand(__bed_to_gff__output,  MARK=MARK_OK))


    def getBAMFilesByMark(wildcards):
        ALL_BAM = expand(__macs2_rep__input_bam, IP_REP=IP_ALL)
        BAM_dict = {}
        for mark in marks:
            BAM_dict[mark] = []
            for file in ALL_BAM:
                if mark in file:
                    BAM_dict[mark].append(file)

        return BAM_dict[wildcards["MARK"]]


    # feature Count on peaks
    __feature_counts__input = getBAMFilesByMark
    __feature_counts__output_count = "9-CountMatrix/{{MARK}}_Matrix_Optimal_{}Peak.mtx".format(model)
    if len(conds) == 2 :
        __feature_counts__gff = "9-CountMatrix/{{MARK}}_{}u{}_{}.optimal.{}Peak_overlap.gff".format(conds[0], conds[1], ref, model)
    elif len(conds) == 3 :
        __feature_counts__gff = "9-CountMatrix/{{MARK}}_{}u{}u{}_{}.optimal.{}Peak_overlap.gff".format(conds[0], conds[1], conds[2], ref, model)
    else :
        __feature_counts__gff = "9-CountMatrix/{{MARK}}_all_conds_{}.optimal.{}Peak_overlap.gff".format(ref, model)
    __feature_counts__log = "9-CountMatrix/logs/{MARK}_counts.o"
    __feature_counts__options = "-t peak -g gene_id"
    __feature_counts__threads = 4
    include: sm.modules["feature_counts"]
    expected_output.extend(expand(__feature_counts__output_count,  MARK=MARK_OK))


    method = manager.config.differential_analysis.method
    norm = manager.config.differential_analysis.normalisation
    # run differential analysis
    __chipuanar__input = __feature_counts__output_count
    __chipuanar__conds = conds
    __chipuanar__rep = rep
    __chipuanar__method = method
    __chipuanar__norm = norm
    if manager.config.differential_analysis.spikes and manager.config.design.spike :
        __chipuanar__spikes = __spikes_counting__output_json
        __chipuanar__input_done = __spikes_counting__output_json
    else:
        __chipuanar__spikes = ""
        __chipuanar__input_done = __feature_counts__output_count
    __chipuanar__padj = manager.config.differential_analysis.pAdjustMethod
    __chipuanar__alpha = manager.config.differential_analysis.alpha
    __chipuanar__batch = manager.config.differential_analysis.batch
    __chipuanar__report = "10-DifferentialAnalysis/{{MARK}}_{}_{}/{{MARK}}_Stat_report_{}_{}.html".format(method, norm, method, norm)
    __chipuanar__output_dir = "10-DifferentialAnalysis/{{MARK}}_{}_{}".format(method, norm)
    __chipuanar__config_r = "10-DifferentialAnalysis/{{MARK}}_{}_{}/config.R".format(method, norm)
    __chipuanar__genome = ref
    include: sm.modules["chipuanar"]
    expected_output.extend(expand(__chipuanar__report,  MARK=MARK_OK))




# !Reset expected_output variable after multiqc
# Multiqc rule
__multiqc__input = expected_output
__multiqc__input_dir = "."
__multiqc__logs = "11-Multiqc/multiqc.log"
__multiqc__output = config['multiqc']['output-directory'] + "/%s/multiqc_report.html" % (model_dir)
include: sm.modules["multiqc"]
expected_output = [__multiqc__output]

# copy IDR metrics in the corresponding multiQC output when you are in exploratory mode
__copy_metrics__input = __metrics_peaks__output
__copy_metrics__output = config['multiqc']['output-directory'] + "/%s/%s_IDR_metrics.txt" % (model_dir, model_dir)
include: dynamic_copy("metrics", manager)
expected_output.extend([__copy_metrics__output])

# Include rule graph for each sample
__rulegraph__input = __snakefile__
__rulegraph__output = "rulegraph/rulegraph.svg"
__rulegraph__mapper = {"fastqc_samples": "fastqc_samples/"}
include: sm.modules['rulegraph']
expected_output.extend([__rulegraph__output])

# Add Conda
__conda__output = "requirements.txt"
include: sm.modules['conda']  # Create requirements.txt(dependencies)
expected_output.extend([__conda__output])

# Those rules takes a couple of seconds so no need for a cluster
localrules: conda, rulegraph

rule chipseq:
    input: expected_output

onsuccess:
    import os
    # Create plots about stats
    sm.plot_stats(N=len(manager.samples))

    try: os.mkdir("cluster_logs")
    except:pass

    try: shell("mv slurm* cluster_logs/")
    except: pass

    #create a file which suppress all PPR, SPR, and deduplicates/blacklist and trimmed files
    sm.OnSuccess()() # create instance to create main cleanup


onerror:
    print("An error occurred. See message above.")
